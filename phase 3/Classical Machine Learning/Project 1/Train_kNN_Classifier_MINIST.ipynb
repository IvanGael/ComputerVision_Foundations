{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Train a k-Nearest Neighbors (kNN) classifier to recognize digits from the MNIST dataset.\n"
      ],
      "metadata": {
        "id": "Nr5og7Kmm0Y8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqf5Vim3jIOZ",
        "outputId": "e4421f5f-a571-4c4e-934e-d0372c4af5c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Data Preparation : load and prepare the MNIST dataset\n",
        "\n",
        "# In this step, we load the MNIST dataset using Keras5. The dataset consists of 60,000 training images\n",
        "# and 10,000 test images, each of size 28x28 pixels4. We reshape the images into 1D arrays\n",
        "# and normalize the pixel values to the range [0, 1].\n",
        "\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Reshape the data\n",
        "X_train = X_train.reshape(X_train.shape[0], -1)\n",
        "X_test = X_test.reshape(X_test.shape[0], -1)\n",
        "\n",
        "# Normalize the data\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.astype('float32') / 255"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the kNN Classifier\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Create and train the kNN classifier\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rg1DfUI6jthG",
        "outputId": "b6e90d13-bc26-4608-d2ec-22214c8aef5d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use scikit-learn's KNeighborsClassifier to create and train our kNN model. We set n_neighbors=5, which means the classifier will consider the 5 nearest neighbors when making predictions."
      ],
      "metadata": {
        "id": "u6a870R0n3SF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation**\n",
        "\n",
        "After training the model and making predictions on the test set, we calculate the accuracy of our classifier.\n",
        "The accuracy represents the proportion of correct predictions among the total number of cases examined."
      ],
      "metadata": {
        "id": "e5oItl26ntSz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Results and Discussion**\n",
        "\n",
        "The kNN classifier typically achieves an accuracy of around 96-97% on the MNIST dataset. This performance is quite good, considering the simplicity of the kNN algorithm. However, it's worth noting that more advanced techniques, such as convolutional neural networks (CNNs),\n",
        "can achieve even higher accuracy on this dataset, often exceeding 99%"
      ],
      "metadata": {
        "id": "5vRn0UPknj0w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Advantages and Limitations of kNN for MNIST**\n",
        "\n",
        "**Advantages:**\n",
        "- Simple to implement and understand\n",
        "- No training phase (lazy learning)\n",
        "- Can perform well on datasets with clear decision boundaries\n",
        "\n",
        "**Limitations:**\n",
        "- Slow prediction time for large datasets\n",
        "- Requires a lot of memory to store the entire training set\n",
        "- Sensitive to irrelevant features and the scale of the data"
      ],
      "metadata": {
        "id": "IrT-kKevnH1E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion**\n",
        "\n",
        "We have successfully trained a k-Nearest Neighbors classifier to recognize handwritten digits from the MNIST dataset.\n",
        "While kNN provides a good baseline performance, more advanced techniques may be necessary for state-of-the-art results\n",
        "on this and similar image classification tasks."
      ],
      "metadata": {
        "id": "cPz6bu3Zm-Zh"
      }
    }
  ]
}